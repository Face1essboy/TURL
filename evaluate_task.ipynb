{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except:\n",
    "    from tensorboardX import SummaryWriter\n",
    "\n",
    "from tqdm import trange\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from data_loader.hybrid_data_loaders import *\n",
    "from data_loader.header_data_loaders import *\n",
    "from data_loader.CT_Wiki_data_loaders import *\n",
    "from model.configuration import TableConfig\n",
    "from model.model import HybridTableMaskedLM, HybridTableCER, TableHeaderRanking, HybridTableCT\n",
    "from model.transformers import BertTokenizer, WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n",
    "from utils.util import *\n",
    "from baselines.row_population.metric import average_precision,ndcg_at_k\n",
    "from baselines.cell_filling.cell_filling import *\n",
    "from model import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'CER': (TableConfig, HybridTableCER, BertTokenizer),\n",
    "    'CF' : (TableConfig, HybridTableMaskedLM, BertTokenizer),\n",
    "    'HR': (TableConfig, TableHeaderRanking, BertTokenizer),\n",
    "    'CT': (TableConfig, HybridTableCT, BertTokenizer)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/wikisql_entity/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of entity: 368793\n",
      "remove because of empty title: 5426\n",
      "remove because count<2: 467625\n"
     ]
    }
   ],
   "source": [
    "config_name = \"configs/table-base-config.json\"\n",
    "device = torch.device('cuda')\n",
    "entity_vocab = load_entity_vocab(data_dir, ignore_bad_title=True, min_ent_count=2)\n",
    "entity_wikid2id = {entity_vocab[x]['wiki_id']:x for x in entity_vocab}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"output/hybrid/model_v1_table_0.2_0.6_0.7_30000_1e-4_with_cand_0\"\n",
    "model = model_class(config, is_simple=True)\n",
    "checkpoint = torch.load(os.path.join(checkpoint, 'pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint['table.embeddings.ent_embeddings.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_loc = \"output/hybrid/model_v1_table_0.2_0.6_0.7_30000_1e-4_with_cand_0\"\n",
    "entity_vocab_with_type = []\n",
    "with open(\"data/wikisql_entity/entity_vocab_with_type.tsv\", 'r', encoding='utf8') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        wiki_id = line.strip().split('\\t')[0]\n",
    "        entity_vocab_with_type.append(int(wiki_id))\n",
    "with open(os.path.join(dump_loc, \"entity_embedding_with_type.tsv\"), \"w\") as f_e:\n",
    "    for wiki_id in entity_vocab_with_type:\n",
    "        f_e.write('{}\\n'.format('\\t'.join([str(z) for z in checkpoint['table.embeddings.ent_embeddings.weight'][entity_wikid2id[wiki_id]].tolist()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WikiHybridTableDataset(data_dir,entity_vocab,max_cell=100, max_input_tok=350, max_input_ent=150, src=\"dev\", max_length = [50, 10, 10], force_new=False, tokenizer = None, mode=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"./output/CER/hybrid/model_v1_table_0.2_0.6_0.7_30000_1e-4_with_cand_0_seed_1_10000/checkpoint-7500/pytorch_model.bin\"\n",
    "\n",
    "\n",
    "config_class, model_class, _ = MODEL_CLASSES['CER']\n",
    "config = config_class.from_pretrained(config_name)\n",
    "config.output_attentions = True\n",
    "\n",
    "model = model_class(config, is_simple=True)\n",
    "checkpoint = torch.load(checkpoint)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entity_set = set(dataset.entity_wikid2id.keys())\n",
    "tables_ignored = 0\n",
    "dev_result = {}\n",
    "cached_baseline = \"data/wikisql_entity/dev_result_CER.pkl\"\n",
    "with open(cached_baseline, \"rb\") as f:\n",
    "    cached_baseline_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 1\n",
    "results = {}\n",
    "with open(os.path.join(data_dir,\"dev_tables.jsonl\"), 'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        table = json.loads(line.strip())\n",
    "        table_id = table.get(\"_id\", \"\")\n",
    "        pgEnt = table[\"pgId\"]\n",
    "        if not pgEnt in all_entity_set:\n",
    "            pgEnt = -1\n",
    "        pgTitle = table.get(\"pgTitle\", \"\").lower()\n",
    "        secTitle = table.get(\"sectionTitle\", \"\").lower()\n",
    "        caption = table.get(\"tableCaption\", \"\").lower()\n",
    "        headers = table.get(\"processed_tableHeaders\", [])\n",
    "        rows = table.get(\"tableData\", {})\n",
    "        entity_columns = table.get(\"entityColumn\", [])\n",
    "        headers = [headers[j] for j in entity_columns]\n",
    "        entity_cells = np.array(table.get(\"entityCell\",[[]]))\n",
    "        core_entities = []\n",
    "        num_rows = len(rows)\n",
    "        for i in range(num_rows):\n",
    "            if entity_cells[i,0] == 1:\n",
    "                entity = rows[i][0]['surfaceLinks'][0]['target']['id']\n",
    "                entity_text = rows[i][0]['text']\n",
    "                core_entities.append([entity_text,entity])\n",
    "        core_entities = [z for z in core_entities if z[1] in all_entity_set]\n",
    "        if len(core_entities) < 5:\n",
    "            tables_ignored += 1\n",
    "            continue\n",
    "        seed_entities = [z[1] for z in core_entities[:seed_num]]\n",
    "        seed_entities_text = [z[0] for z in core_entities[:seed_num]]\n",
    "        target_entities = set([z[1] for z in core_entities[seed_num:]])\n",
    "        seeds_1, _, _, pall, pee, pce, ple, cand_e, cand_c = cached_baseline_result[table_id]\n",
    "        if len(target_entities) == 0:\n",
    "            tables_ignored += 1\n",
    "            continue\n",
    "        results[table_id] = {}\n",
    "        assert seeds_1 == set(seed_entities)\n",
    "        cand_e = set([z for z in cand_e if z in all_entity_set and z not in seed_entities])\n",
    "        cand_c = set([z for z in cand_c if z in all_entity_set and z not in seed_entities])\n",
    "        entity_cand = list(cand_e|cand_c)\n",
    "        \n",
    "        pee = {k:v for k,v in pee.items() if k in entity_cand}\n",
    "        pce = {k:v for k,v in pce.items() if k in entity_cand}\n",
    "        ple = {k:v for k,v in ple.items() if k in entity_cand}\n",
    "        pall = {k:v for k,v in pall.items() if k in entity_cand}\n",
    "\n",
    "        input_tok, input_tok_type, input_tok_pos, input_mask,\\\n",
    "            input_ent, input_ent_text, input_ent_text_length, input_ent_type, candidate_entity_set = CER_build_input(pgEnt, pgTitle, secTitle, caption, headers[0], seed_entities, seed_entities_text, entity_cand, dataset)\n",
    "        \n",
    "        input_tok = input_tok.to(device)\n",
    "        input_tok_type = input_tok_type.to(device)\n",
    "        input_tok_pos = input_tok_pos.to(device)\n",
    "        input_ent = input_ent.to(device)\n",
    "        input_ent_text = input_ent_text.to(device)\n",
    "        input_ent_text_length = input_ent_text_length.to(device)\n",
    "        input_ent_type = input_ent_type.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        candidate_entity_set = candidate_entity_set.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ent_outputs = model(input_tok, input_tok_type, input_tok_pos, input_mask,\n",
    "                            input_ent, input_ent_text, input_ent_text_length, input_ent_type, input_mask,\n",
    "                            candidate_entity_set, None, None)\n",
    "            ent_prediction_scores = ent_outputs[0][0].tolist()\n",
    "\n",
    "            p_neural = {}\n",
    "            \n",
    "            for i, entity in enumerate(entity_cand):\n",
    "                p_neural[entity] = ent_prediction_scores[i]\n",
    "        results[table_id] = {\n",
    "            'pgTitle': pgTitle,\n",
    "            'secTitle': secTitle,\n",
    "            'caption': caption,\n",
    "            'headers': headers,\n",
    "            'cand_all': entity_cand,\n",
    "            'cand_e': cand_e,\n",
    "            'cand_c': cand_c,\n",
    "            'seed_e': seed_entities,\n",
    "            'target_e': target_entities,\n",
    "            'p_neural': p_neural,\n",
    "            'pee': pee,\n",
    "            'pce': pce,\n",
    "            'ple': ple,\n",
    "            'pall': pall\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('recall all', \\\n",
    "      np.mean([len(set(x['cand_all'])&x['target_e'])/len(x['target_e']) for _,x in results.items()]), \\\n",
    "      np.mean([len(set(x['cand_all'])) for _,x in results.items()]))\n",
    "print('recall e', \\\n",
    "      np.mean([len(x['cand_e']&x['target_e'])/len(x['target_e']) for _,x in results.items()]), \\\n",
    "      np.mean([len(set(x['cand_e'])) for _,x in results.items()]))\n",
    "print('recall c', \\\n",
    "      np.mean([len(x['cand_c']&x['target_e'])/len(x['target_e']) for _,x in results.items()]), \\\n",
    "      np.mean([len(set(x['cand_c'])) for _,x in results.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ap(scores, target_e):\n",
    "    ranked = sorted(scores.items(),key=lambda z:z[1],reverse=True)\n",
    "    ranked_l = [1 if z[0] in target_e else 0 for z in ranked]\n",
    "    ap = average_precision(ranked_l)\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('map neural', np.mean([get_ap(x['p_neural'],x['target_e']) for _,x in results.items()]))\n",
    "print('map neural - only cand_e', np.mean([get_ap({z:score if z in x['cand_e'] else -10000 for z, score in x['p_neural'].items()},x['target_e']) for _,x in results.items()]))\n",
    "print('map ee', np.mean([get_ap(x['pee'],x['target_e']) for _,x in results.items()]))\n",
    "print('map le', np.mean([get_ap(x['ple'],x['target_e']) for _,x in results.items()]))\n",
    "print('map ce', np.mean([get_ap(x['pce'],x['target_e']) for _,x in results.items()]))\n",
    "print('map all', np.mean([get_ap(x['pall'],x['target_e']) for _,x in results.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in [0.999, 0.99, 0.9, 0.5, 0.1, 0.05, 0.06, 0.07, 0.08, 0.09, 0.01]:\n",
    "    print('map neural - ensemble {}'.format(w), np.mean([get_ap({z:w*score+(1-w)*x['pee'][z] for z, score in x['p_neural'].items()},x['target_e']) for _,x in results.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_ids = []\n",
    "for table_id, x in results.items():\n",
    "    recall = len(set(x['cand_all'])&x['target_e'])/len(x['target_e'])\n",
    "    ap_neural = get_ap(x['p_neural'],x['target_e'])\n",
    "    ap_ee = get_ap(x['pee'],x['target_e'])\n",
    "    if recall != 0 and (ap_neural < 0.4 or ap_neural < ap_ee):\n",
    "        inspect_ids.append(table_id)\n",
    "print(len(inspect_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_result(result):\n",
    "    ap_neural = get_ap(result['p_neural'],result['target_e'])\n",
    "    ap_ee = get_ap(result['pee'],result['target_e'])\n",
    "    print('ap_neural: {}\\nap_ee: {}'.format(ap_neural, ap_ee))\n",
    "    print('{} - {} - {}'.format(result['pgTitle'], result['secTitle'], result['caption']))\n",
    "    print(result['headers'])\n",
    "    print('seed:')\n",
    "    print('; '.join([entity_vocab[entity_wikid2id[e]]['wiki_title'] for e in result['seed_e']]))\n",
    "    target_entities = [entity_vocab[entity_wikid2id[z]] for z in result['target_e']]\n",
    "    print('target:\\n%s'%('; '.join([z['wiki_title'] for z in target_entities])))\n",
    "    ranked_neural = sorted(result['p_neural'].items(),key=lambda z:z[1],reverse=True)\n",
    "    print('neural:')\n",
    "    print('; '.join([\n",
    "        '[%s:%f]'%(entity_vocab[entity_wikid2id[e]]['wiki_title'],score) if e in result['target_e'] \\\n",
    "        else '%s:%.2f'%(entity_vocab[entity_wikid2id[e]]['wiki_title'],score)\n",
    "    for e,score in ranked_neural[:10]]))\n",
    "    ranked_e = sorted(result['pee'].items(),key=lambda z:z[1],reverse=True)\n",
    "    print('ee:')\n",
    "    print('; '.join([\n",
    "        '[%s:%f]'%(entity_vocab[entity_wikid2id[e]]['wiki_title'],score) if e in result['target_e'] \\\n",
    "        else '%s:%.2f'%(entity_vocab[entity_wikid2id[e]]['wiki_title'],score)\n",
    "    for e,score in ranked_e[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_result(results[inspect_ids[3]])\n",
    "print(len([id for id in inspect_ids if results[id]['headers'][0] in ['opponent', 'team 1', 'home team']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_result(results[inspect_ids[6]])\n",
    "print(len([id for id in inspect_ids if 'miss dominican republic' in results[id]['pgTitle']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_result(results[inspect_ids[32]])\n",
    "print(len([id for id in inspect_ids if results[id]['headers'][0]=='constituency']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_class, model_class, _ = MODEL_CLASSES['CF']\n",
    "config = config_class.from_pretrained(config_name)\n",
    "config.output_attentions = True\n",
    "\n",
    "checkpoint = \"output/hybrid/model_v1_table_0.2_0.6_0.7_30000_1e-4_with_cand_0\"\n",
    "model = model_class(config, is_simple=True)\n",
    "checkpoint = torch.load(os.path.join(checkpoint, 'pytorch_model.bin'))\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "CF = cell_filling(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir,\"CF_dev_data.json\"), 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "dataset = WikiHybridTableDataset(data_dir,entity_vocab,max_cell=100, max_input_tok=350, max_input_ent=150, src=\"dev\", max_length = [50, 10, 10], force_new=False, tokenizer = None, mode=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for table_id,pgEnt,pgTitle,secTitle,caption,(h1, h2),data_sample in tqdm(dev_data):\n",
    "    core_entities = []\n",
    "    core_entities_text = []\n",
    "    target_entities = []\n",
    "    all_entity_cand = set()\n",
    "    entity_cand = []\n",
    "    for (core_e, core_e_text), target_e in data_sample:\n",
    "        assert target_e in entity_wikid2id\n",
    "        core_entities.append(core_e)\n",
    "        core_entities_text.append(core_e_text)\n",
    "        target_entities.append(target_e)\n",
    "        cands = CF.get_cand_row(core_e, h2)\n",
    "        cands = {key:value for key,value in cands.items() if key in entity_wikid2id}\n",
    "        entity_cand.append(cands)\n",
    "        all_entity_cand |= set(cands.keys()) \n",
    "    all_entity_cand = list(all_entity_cand)\n",
    "    input_tok, input_tok_type, input_tok_pos, input_tok_mask,\\\n",
    "        input_ent, input_ent_text, input_ent_text_length, input_ent_type, input_ent_mask, \\\n",
    "        candidate_entity_set = CF_build_input(pgEnt, pgTitle, secTitle, caption, [h1, h2], core_entities, core_entities_text, all_entity_cand, dataset)\n",
    "    input_tok = input_tok.to(device)\n",
    "    input_tok_type = input_tok_type.to(device)\n",
    "    input_tok_pos = input_tok_pos.to(device)\n",
    "    input_tok_mask = input_tok_mask.to(device)\n",
    "    input_ent_text = input_ent_text.to(device)\n",
    "    input_ent_text_length = input_ent_text_length.to(device)\n",
    "    input_ent = input_ent.to(device)\n",
    "    input_ent_type = input_ent_type.to(device)\n",
    "    input_ent_mask = input_ent_mask.to(device)\n",
    "    candidate_entity_set = candidate_entity_set.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, ent_outputs = model(input_tok, input_tok_type, input_tok_pos, input_tok_mask,\n",
    "                        input_ent_text, input_ent_text_length, None,\n",
    "                        input_ent, input_ent_type, input_ent_mask, candidate_entity_set)\n",
    "        num_sample = len(target_entities)\n",
    "        ent_prediction_scores = ent_outputs[0][0,num_sample+1:].tolist()\n",
    "    result = []\n",
    "    for i, target_e in enumerate(target_entities):\n",
    "        predictions = ent_prediction_scores[i]\n",
    "        if len(entity_cand[i]) == 0:\n",
    "            continue\n",
    "        tmp_cand_scores = []\n",
    "        for j, cand_e in enumerate(all_entity_cand):\n",
    "            if cand_e in entity_cand[i]:\n",
    "                tmp_cand_scores.append([cand_e, predictions[j]])\n",
    "        sorted_cand_scores =  sorted(tmp_cand_scores, key=lambda z:z[1], reverse=True)\n",
    "        sorted_cands = [z[0] for z in sorted_cand_scores]\n",
    "        base_sorted_cands = CF.rank_cand_h(h2, entity_cand[i])\n",
    "        result.append([target_e, entity_cand[i], sorted_cands, base_sorted_cands])\n",
    "    results.append({\n",
    "            'pgTitle': pgTitle,\n",
    "            'secTitle': secTitle,\n",
    "            'caption': caption,\n",
    "            'headers': [h1, h2],\n",
    "            'result': result\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(result):\n",
    "    recall = 0\n",
    "    precision_neural = [0, 0, 0, 0]\n",
    "    precision_base = [0, 0, 0, 0]\n",
    "    for target_e, cand, p_neural, p_base in result:\n",
    "        if target_e in cand:\n",
    "            recall += 1\n",
    "        if target_e == p_neural[0]:\n",
    "            precision_neural[0] += 1\n",
    "        if target_e == p_base[0]:\n",
    "            precision_base[0] += 1\n",
    "        if target_e in p_neural[:3]:\n",
    "            precision_neural[1] += 1\n",
    "        if target_e in p_neural[:5]:\n",
    "            precision_neural[2] += 1\n",
    "        if target_e in p_neural[:10]:\n",
    "            precision_neural[3] += 1\n",
    "        if target_e in p_base[:3]:\n",
    "            precision_base[1] += 1\n",
    "        if target_e in p_base[:5]:\n",
    "            precision_base[2] += 1\n",
    "        if target_e in p_base[:10]:\n",
    "            precision_base[3] += 1\n",
    "    if recall != 0:\n",
    "        return recall/len(result), [z/recall for z in precision_neural], [z/recall for z in precision_base]\n",
    "    else:\n",
    "        return 0, [0 for z in precision_neural], [0 for z in precision_base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = [get_precision(x['result']) for x in results]\n",
    "print('recall', np.mean([x[0] for x in final_results]))\n",
    "print('neural')\n",
    "print('p@1', np.mean([x[1][0] for x in final_results if x[0]!=0]))\n",
    "print('p@3', np.mean([x[1][1] for x in final_results if x[0]!=0]))\n",
    "print('p@5', np.mean([x[1][2] for x in final_results if x[0]!=0]))\n",
    "print('p@10', np.mean([x[1][3] for x in final_results if x[0]!=0]))\n",
    "print('base')\n",
    "print('p@1', np.mean([x[2][0] for x in final_results if x[0]!=0]))\n",
    "print('p@3', np.mean([x[2][1] for x in final_results if x[0]!=0]))\n",
    "print('p@5', np.mean([x[2][2] for x in final_results if x[0]!=0]))\n",
    "print('p@10', np.mean([x[2][3] for x in final_results if x[0]!=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('neural')\n",
    "print('p@1', np.mean([x[1][0] for i,x in enumerate(final_results) if x[0]!=0 and 'team' not in results[i]['headers'][1]]))\n",
    "print('p@3', np.mean([x[1][1] for i,x in enumerate(final_results) if x[0]!=0 and 'team' not in results[i]['headers'][1]]))\n",
    "print('p@5', np.mean([x[1][2] for i,x in enumerate(final_results) if x[0]!=0 and 'team' not in results[i]['headers'][1]]))\n",
    "print('p@10', np.mean([x[1][3] for i,x in enumerate(final_results) if x[0]!=0 and 'team' not in results[i]['headers'][1]]))\n",
    "print('base')\n",
    "print('p@1', np.mean([x[2][0] for i,x in enumerate(final_results) if x[0]!=0 and 'team' not in results[i]['headers'][1]]))\n",
    "print('p@3', np.mean([x[2][1] for i,x in enumerate(final_results) if x[0]!=0 and 'team' not in results[i]['headers'][1]]))\n",
    "print('p@5', np.mean([x[2][2] for i,x in enumerate(final_results) if x[0]!=0 and 'team' not in results[i]['headers'][1]]))\n",
    "print('p@10', np.mean([x[2][3] for i,x in enumerate(final_results) if x[0]!=0 and 'team' not in results[i]['headers'][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_headers = Counter([results[i]['headers'][1] for i,x in enumerate(final_results) if x[0]!=0 and x[1][0]>x[2][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_headers.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worse_headers = Counter([results[i]['headers'][1] for i,x in enumerate(final_results) if x[0]!=0 and x[1][0]<x[2][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worse_headers.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_headers = Counter([' | '.join(results[i]['headers']) for i,x in enumerate(final_results) if x[0]!=0 and x[1][0]<0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_headers.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_headers = Counter([' | '.join(results[i]['headers']) for i,x in enumerate(final_results) if x[0]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_headers.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_class, model_class, _ = MODEL_CLASSES['HR']\n",
    "config = config_class.from_pretrained(config_name)\n",
    "config.output_attentions = True\n",
    "\n",
    "train_dataset = WikiHeaderDataset(data_dir,max_input_tok=350, src=\"train\", max_length = [50, 10], force_new=False, tokenizer = None)\n",
    "eval_dataset = WikiHeaderDataset(data_dir,max_input_tok=350, src=\"dev\", max_length = [50, 10], force_new=False, tokenizer = None)\n",
    "config.__dict__['header_vocab_size'] = len(eval_dataset.header_vocab)\n",
    "\n",
    "checkpoint = \"output/HR/hybrid/model_v1_table_0.2_0.4_0.7_30000_1e-4_with_cand_0_seed_0/checkpoint-130000/\"\n",
    "# checkpoint = \"output/HR/bert_seed_0/\"\n",
    "model = model_class(config, is_simple=True)\n",
    "checkpoint = torch.load(os.path.join(checkpoint, 'pytorch_model.bin'))\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch_size = 64\n",
    "eval_sampler = SequentialSampler(eval_dataset)\n",
    "eval_dataloader = WikiHeaderLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size,is_train=False,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "    _,input_tok, input_tok_type, input_tok_pos, \\\n",
    "            input_header, input_header_type, \\\n",
    "            input_mask, seed_header, target_header = batch\n",
    "    input_tok = input_tok.to(device)\n",
    "    input_tok_type = input_tok_type.to(device)\n",
    "    input_tok_pos = input_tok_pos.to(device)\n",
    "    input_header = input_header.to(device)\n",
    "    input_header_type = input_header_type.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    seed_header = seed_header.to(device)\n",
    "    target_header = target_header.to(device)\n",
    "    with torch.no_grad():\n",
    "        header_outputs = model(input_tok, input_tok_type, input_tok_pos,\n",
    "                        input_header, input_header_type, input_mask,\n",
    "                        seed_header, target_header)\n",
    "        header_loss = header_outputs[0]\n",
    "        header_prediction_scores = header_outputs[1]\n",
    "        results.extend(header_prediction_scores.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ap(scores, target_e):\n",
    "    ranked = np.argsort(scores)[::-1]\n",
    "    target_e = set(target_e)\n",
    "    ranked_l = [1 if z in target_e else 0 for z in ranked]\n",
    "    ap = average_precision(ranked_l)\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = []\n",
    "for i, x in tqdm(enumerate(results)):\n",
    "    maps.append(get_ap(x, eval_dataset[i][5][1:]))\n",
    "print(np.mean(maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [i for i,ap in enumerate(maps) if ap<0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display([eval_dataset.header_vocab[x] for x in np.argsort(results[1])[::-1][:10]])\n",
    "display([eval_dataset.header_vocab[x] for x in eval_dataset[1][5][1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.tokenizer.decode(eval_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(i):\n",
    "    print(eval_dataset.tokenizer.decode(eval_dataset[i][1]))\n",
    "    print(maps[i])\n",
    "    print('; '.join([eval_dataset.header_vocab[x] for x in np.argsort(results[i])[::-1][:10]]))\n",
    "    print('; '.join([eval_dataset.header_vocab[x] for x in eval_dataset[i][5][1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(errors[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_loc = \"output/HR/hybrid/model_v1_table_0.2_0.4_0.7_30000_1e-4_with_cand_0_seed_0/\"\n",
    "with open(os.path.join(dump_loc, \"header_embedding.tsv\"), \"w\") as f_e, open(os.path.join(dump_loc, \"header_names.tsv\"), \"w\", encoding='utf8') as f_n:\n",
    "    for i, name in eval_dataset.header_vocab.items():\n",
    "        f_n.write('{}\\n'.format(name))\n",
    "        f_e.write('{}\\n'.format('\\t'.join([str(z) for z in model.cls.weight.data[i].tolist()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer=lambda x:x,\n",
    "    token_pattern=None)\n",
    "train_tfidf = tfidf.fit_transform([x[1] for x in train_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.transform([eval_dataset[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=1,metric='cosine')\n",
    "neigh.fit(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "for k in [1,3,5,10]:\n",
    "    print(k)\n",
    "    maps_base = []\n",
    "    recalls = []\n",
    "    for x in tqdm(eval_dataset):\n",
    "        header_count = Counter()\n",
    "        neighbor = neigh.kneighbors(tfidf.transform([x[1]]), k, return_distance=False)\n",
    "        for n in neighbor.reshape([-1]):\n",
    "            header_count.update(train_dataset[n][5][1:])\n",
    "        target_e = set(x[5][1:])\n",
    "        recalls.append(len([z for z in header_count if z in target_e])/len(target_e))\n",
    "        ap = average_precision([1 if z in target_e else 0 for z,_ in header_count.most_common()]+[1 if z in target_e else 0 for z in range(config.header_vocab_size) if z not in header_count])\n",
    "        maps_base.append(ap)\n",
    "    print(np.mean(maps_base))\n",
    "    print(np.mean(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "for k in [15,30,50,100]:\n",
    "    print(k)\n",
    "    maps_base = []\n",
    "    recalls = []\n",
    "    for x in tqdm(eval_dataset):\n",
    "        header_count = Counter()\n",
    "        neighbor = neigh.kneighbors(tfidf.transform([x[1]]), k, return_distance=False)\n",
    "        for n in neighbor.reshape([-1]):\n",
    "            header_count.update(train_dataset[n][5][1:])\n",
    "        target_e = set(x[5][1:])\n",
    "        recalls.append(len([z for z in header_count if z in target_e])/len(target_e))\n",
    "        ap = average_precision([1 if z in target_e else 0 for z,_ in header_count.most_common()]+[1 if z in target_e else 0 for z in range(config.header_vocab_size) if z not in header_count])\n",
    "        maps_base.append(ap)\n",
    "    print(np.mean(maps_base))\n",
    "    print(np.mean(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.header_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try loading preprocessed data from data/wikisql_entity/procressed_WikiCT/dev.pickle\n"
     ]
    }
   ],
   "source": [
    "type_vocab = load_type_vocab(\"./data/wikisql_entity\")\n",
    "eval_dataset = WikiCTDataset(data_dir, entity_vocab, type_vocab, max_input_tok=500, src=\"dev\", max_length = [50, 10, 10], force_new=False, tokenizer = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(output, relevance_labels):\n",
    "    with torch.no_grad():\n",
    "        sorted_output = torch.argsort(output, dim=-1, descending=True)\n",
    "        sorted_labels = torch.gather(relevance_labels, -1, sorted_output).float()\n",
    "        cum_correct = torch.cumsum(sorted_labels, dim=-1)\n",
    "        cum_precision = cum_correct / torch.arange(start=1,end=cum_correct.shape[-1]+1, device=cum_correct.device)[None, :]\n",
    "        cum_precision = cum_precision * sorted_labels\n",
    "        total_valid = torch.sum(sorted_labels, dim=-1)\n",
    "        total_valid[total_valid==0] = 1\n",
    "        average_precision = torch.sum(cum_precision, dim=-1)/total_valid\n",
    "\n",
    "    return average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_type_accuracy = {}\n",
    "per_type_precision = {}\n",
    "per_type_recall = {}\n",
    "per_type_f1 = {}\n",
    "map = {}\n",
    "precision = {}\n",
    "recall = {}\n",
    "f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70aab6a9edd417fadf2074ae102c6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=232, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9902757586076342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa818362c5ff4fa4962f022811180a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=232, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9831231909579244\n",
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d517ba44a04117a1e10f9544d77806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=232, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.964737164049313\n",
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9522397c9b2e46afb04e32da9e533ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=232, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9820393208285858\n",
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e28bbc28ed45669ab965333250e3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=232, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9482440655601436\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "checkpoints = [\n",
    "    \"output/CT/0/model_v1_table_0.2_0.4_0.7_30000_1e-4_with_cand_0/checkpoint-20000/pytorch_model.bin\",\n",
    "    \"output/CT/1/model_v1_table_0.2_0.4_0.7_30000_1e-4_with_cand_0/checkpoint-20000/pytorch_model.bin\",\n",
    "    \"output/CT/2/model_v1_table_0.2_0.4_0.7_30000_1e-4_with_cand_0/checkpoint-20000/pytorch_model.bin\",\n",
    "    \"output/CT/3/model_v1_table_0.2_0.4_0.7_30000_1e-4_with_cand_0/checkpoint-20000/pytorch_model.bin\",\n",
    "    \"output/CT/4/model_v1_table_0.2_0.4_0.7_30000_1e-4_with_cand_0/checkpoint-20000/pytorch_model.bin\"\n",
    "]\n",
    "for mode in [0,1,2,3,4]:\n",
    "    print(mode)\n",
    "    config_class, model_class, _ = MODEL_CLASSES['CT']\n",
    "    config = config_class.from_pretrained(config_name)\n",
    "    config.class_num = len(type_vocab)\n",
    "    config.mode = mode\n",
    "    model = model_class(config, is_simple=True)\n",
    "    checkpoint = checkpoints[mode]\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    eval_batch_size = 20\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = CTLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size, is_train=False)\n",
    "    eval_loss = 0.0\n",
    "    eval_map = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    eval_targets = []\n",
    "    eval_prediction_scores = []\n",
    "    eval_pred = []\n",
    "    eval_mask = []\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        table_id, input_tok, input_tok_type, input_tok_pos, input_tok_mask, \\\n",
    "            input_ent_text, input_ent_text_length, input_ent, input_ent_type, input_ent_mask, \\\n",
    "            column_entity_mask, column_header_mask, labels_mask, labels = batch\n",
    "        input_tok = input_tok.to(device)\n",
    "        input_tok_type = input_tok_type.to(device)\n",
    "        input_tok_pos = input_tok_pos.to(device)\n",
    "        input_tok_mask = input_tok_mask.to(device)\n",
    "        input_ent_text = input_ent_text.to(device)\n",
    "        input_ent_text_length = input_ent_text_length.to(device)\n",
    "        input_ent = input_ent.to(device)\n",
    "        input_ent_type = input_ent_type.to(device)\n",
    "        input_ent_mask = input_ent_mask.to(device)\n",
    "        column_entity_mask = column_entity_mask.to(device)\n",
    "        column_header_mask = column_header_mask.to(device)\n",
    "        labels_mask = labels_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if mode == 1:\n",
    "            input_ent_mask = input_ent_mask[:,:,input_tok_mask.shape[1]:]\n",
    "            input_tok = None\n",
    "            input_tok_type = None\n",
    "            input_tok_pos = None\n",
    "            input_tok_mask = None\n",
    "        elif mode == 2:\n",
    "            input_tok_mask = input_tok_mask[:,:,:input_tok_mask.shape[1]]\n",
    "            input_ent_text = None\n",
    "            input_ent_text_length = None\n",
    "            input_ent = None\n",
    "            input_ent_type = None\n",
    "            input_ent_mask = None\n",
    "        elif mode == 3:\n",
    "            input_ent = None\n",
    "        elif mode == 4:\n",
    "            input_ent_mask = input_ent_mask[:,:,input_tok_mask.shape[1]:]\n",
    "            input_tok = None\n",
    "            input_tok_type = None\n",
    "            input_tok_pos = None\n",
    "            input_tok_mask = None\n",
    "            input_ent = None\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tok, input_tok_type, input_tok_pos, input_tok_mask,\\\n",
    "                input_ent_text, input_ent_text_length, input_ent, input_ent_type, input_ent_mask, column_entity_mask, column_header_mask, labels_mask, labels)\n",
    "            loss = outputs[0]\n",
    "            prediction_scores = outputs[1]\n",
    "            # pdb.set_trace()\n",
    "            ap = metric.average_precision(prediction_scores.view(-1, config.class_num), labels.view((-1, config.class_num)))\n",
    "            map = (ap*labels_mask.view(-1)).sum()/labels_mask.sum()\n",
    "            eval_loss += loss.mean().item()\n",
    "            eval_map += map.item()\n",
    "            eval_targets.extend(labels.view(-1, config.class_num).tolist())\n",
    "            eval_prediction_scores.extend(prediction_scores.view(-1, config.class_num).tolist())\n",
    "            eval_pred.extend((torch.sigmoid(prediction_scores.view(-1, config.class_num))>0.5).tolist())\n",
    "            eval_mask.extend(labels_mask.view(-1).tolist())\n",
    "        nb_eval_steps += 1\n",
    "    print(eval_map/nb_eval_steps)\n",
    "    eval_targets = np.array(eval_targets)\n",
    "    eval_prediction_scores = np.array(eval_prediction_scores)\n",
    "    eval_mask = np.array(eval_mask)\n",
    "    eval_prediction_ranks = np.argsort(np.argsort(-eval_prediction_scores))\n",
    "    eval_pred = np.array(eval_pred)\n",
    "    eval_tp = eval_mask[:,np.newaxis]*eval_pred*eval_targets\n",
    "    eval_precision = np.sum(eval_tp,axis=0)/np.sum(eval_mask[:,np.newaxis]*eval_pred,axis=0)\n",
    "    eval_precision = np.nan_to_num(eval_precision, 1)\n",
    "    eval_recall = np.sum(eval_tp,axis=0)/np.sum(eval_mask[:,np.newaxis]*eval_targets,axis=0)\n",
    "    eval_recall = np.nan_to_num(eval_recall, 1)\n",
    "    eval_f1 = 2*eval_precision*eval_recall/(eval_precision+eval_recall)\n",
    "    eval_f1 = np.nan_to_num(eval_f1, 0)\n",
    "    per_type_instance_num = np.sum(eval_mask[:,np.newaxis]*eval_targets,axis=0)\n",
    "    per_type_correct_instance_num = np.sum(eval_mask[:,np.newaxis]*(eval_prediction_ranks<eval_targets.sum(axis=1)[:,np.newaxis])*eval_targets,axis=0)\n",
    "    per_type_accuracy[mode] = per_type_correct_instance_num/per_type_instance_num\n",
    "    per_type_precision[mode] = eval_precision\n",
    "    per_type_recall[mode] = eval_recall\n",
    "    per_type_f1[mode] = eval_f1\n",
    "    precision[mode] = np.sum(eval_tp)/np.sum(eval_mask[:,np.newaxis]*eval_pred)\n",
    "    recall[mode] = np.sum(eval_tp)/np.sum(eval_mask[:,np.newaxis]*eval_targets)\n",
    "    f1[mode] = 2*precision[mode]*recall[mode]/(precision[mode]+recall[mode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music.group_member 16.000 0.875 0.750 0.750 0.875  0.125\n",
      "\n",
      "people.family_member 6.000 0.667 0.667 0.667 0.833  0.500\n",
      "\n",
      "theater.theater_genre 2.000 1.000 1.000 1.000 1.000  0.500\n",
      "\n",
      "book.written_work 2.000 0.000 0.500 0.000 0.000  0.000\n",
      "\n",
      "soccer.football_league_season 20.000 0.950 0.950 0.850 1.000  0.900\n",
      "\n",
      "cricket.cricket_stadium 8.000 1.000 1.000 1.000 1.000  1.000\n",
      "\n",
      "location.location 2480.000 0.998 0.992 0.987 0.995  0.971\n",
      "\n",
      "education.educational_institution 132.000 0.992 0.977 0.917 0.962  0.939\n",
      "\n",
      "royalty.noble_person 25.000 0.960 0.960 0.960 0.960  0.960\n",
      "\n",
      "tv.tv_producer 5.000 0.600 0.600 0.400 0.600  0.400\n",
      "\n",
      "time.event 1349.000 0.993 0.993 0.938 0.985  0.979\n",
      "\n",
      "film.music_contributor 13.000 0.692 0.615 0.846 0.692  0.385\n",
      "\n",
      "film.film_genre 17.000 0.941 0.941 0.941 1.000  0.941\n",
      "\n",
      "royalty.kingdom 3.000 1.000 1.000 0.667 1.000  0.333\n",
      "\n",
      "location.capital_of_administrative_division 51.000 0.725 0.588 0.549 0.627  0.255\n",
      "\n",
      "biology.organism 1.000 0.000 1.000 0.000 0.000  0.000\n",
      "\n",
      "music.musical_group 9.000 1.000 0.556 0.556 0.778  0.222\n",
      "\n",
      "sports.sports_facility 126.000 0.984 0.976 0.952 0.992  0.960\n",
      "\n",
      "book.author 35.000 0.829 0.771 0.714 0.714  0.571\n",
      "\n",
      "music.album 9.000 1.000 0.889 1.000 1.000  0.333\n",
      "\n",
      "music.record_label 11.000 1.000 1.000 1.000 1.000  0.727\n",
      "\n",
      "location.jp_prefecture 21.000 1.000 1.000 1.000 0.905  1.000\n",
      "\n",
      "cvg.computer_videogame 9.000 1.000 0.889 0.889 1.000  1.000\n",
      "\n",
      "tv.tv_program 37.000 0.973 1.000 0.973 0.973  0.811\n",
      "\n",
      "basketball.basketball_conference 13.000 1.000 1.000 0.923 1.000  0.923\n",
      "\n",
      "film.producer 17.000 0.882 0.765 0.882 0.941  0.353\n",
      "\n",
      "government.political_party 280.000 1.000 0.993 0.957 1.000  0.975\n",
      "\n",
      "ice_hockey.hockey_position 29.000 1.000 1.000 0.966 1.000  1.000\n",
      "\n",
      "sports.boxer 4.000 0.750 0.750 0.750 0.750  0.500\n",
      "\n",
      "location.australian_local_government_area 10.000 1.000 1.000 1.000 1.000  0.900\n",
      "\n",
      "cvg.cvg_publisher 18.000 0.833 0.833 0.889 0.833  0.667\n",
      "\n",
      "fictional_universe.fictional_character 18.000 1.000 0.833 0.778 0.889  0.389\n",
      "\n",
      "organization.organization 2248.000 0.968 0.969 0.919 0.944  0.907\n",
      "\n",
      "metropolitan_transit.transit_stop 17.000 1.000 0.765 0.941 0.941  0.706\n",
      "\n",
      "location.us_county 42.000 0.976 0.952 0.976 1.000  0.857\n",
      "\n",
      "sports.tournament_event_competition 5.000 1.000 0.600 1.000 1.000  0.400\n",
      "\n",
      "location.administrative_division 359.000 0.961 0.944 0.914 0.955  0.758\n",
      "\n",
      "music.composer 11.000 0.727 0.818 0.818 0.818  0.364\n",
      "\n",
      "government.politician 457.000 0.976 0.952 0.965 0.969  0.956\n",
      "\n",
      "government.election 8.000 1.000 1.000 0.375 0.875  0.375\n",
      "\n",
      "royalty.chivalric_order_member 5.000 0.800 0.600 0.000 0.800  0.200\n",
      "\n",
      "medicine.anatomical_structure 2.000 1.000 1.000 1.000 1.000  1.000\n",
      "\n",
      "sports.sports_position 98.000 0.990 0.990 0.969 0.990  0.969\n",
      "\n",
      "film.production_company 9.000 0.778 0.889 0.667 0.667  0.778\n",
      "\n",
      "architecture.structure 305.000 1.000 0.990 0.990 0.993  0.984\n",
      "\n",
      "location.uk_statistical_location 12.000 1.000 0.917 0.917 0.917  0.750\n",
      "\n",
      "tv.tv_program_creator 15.000 0.733 0.733 0.600 0.600  0.667\n",
      "\n",
      "tennis.tennis_player 66.000 1.000 0.970 0.970 0.970  0.833\n",
      "\n",
      "soccer.football_award 38.000 0.895 0.895 0.895 0.868  0.868\n",
      "\n",
      "geography.geographical_feature 22.000 0.864 0.864 0.864 0.909  0.727\n",
      "\n",
      "tv.tv_series_season 5.000 1.000 0.800 1.000 1.000  0.800\n",
      "\n",
      "soccer.fifa 27.000 1.000 0.963 0.889 1.000  0.963\n",
      "\n",
      "government.political_appointer 4.000 0.750 0.750 0.750 0.750  0.750\n",
      "\n",
      "automotive.company 15.000 1.000 0.933 0.933 0.933  0.933\n",
      "\n",
      "aviation.aircraft_owner 2.000 1.000 0.500 1.000 1.000  0.500\n",
      "\n",
      "government.legislative_session 35.000 1.000 1.000 0.771 1.000  0.943\n",
      "\n",
      "military.military_conflict 4.000 1.000 1.000 0.250 0.750  1.000\n",
      "\n",
      "sports.sports_championship_event 24.000 0.958 0.958 0.750 0.833  0.542\n",
      "\n",
      "olympics.olympic_games 6.000 1.000 1.000 0.833 1.000  0.667\n",
      "\n",
      "broadcast.radio_station 12.000 1.000 1.000 1.000 1.000  0.917\n",
      "\n",
      "music.artist 59.000 0.915 0.932 0.864 0.881  0.492\n",
      "\n",
      "soccer.football_player 130.000 1.000 0.985 0.985 1.000  0.923\n",
      "\n",
      "ice_hockey.hockey_team 103.000 0.981 1.000 0.913 0.951  0.961\n",
      "\n",
      "boats.ship 6.000 1.000 0.667 0.833 0.667  0.500\n",
      "\n",
      "education.school 16.000 1.000 1.000 0.812 0.875  1.000\n",
      "\n",
      "basketball.basketball_player 52.000 1.000 0.942 1.000 1.000  0.750\n",
      "\n",
      "sports.multi_event_tournament 6.000 0.833 0.667 0.833 0.667  0.667\n",
      "\n",
      "award.award_presenting_organization 5.000 1.000 1.000 1.000 1.000  1.000\n",
      "\n",
      "location.hud_county_place 95.000 0.958 0.905 0.853 0.947  0.695\n",
      "\n",
      "government.government_office_or_title 12.000 0.917 1.000 0.333 0.833  0.750\n",
      "\n",
      "boats.ship_class 4.000 1.000 1.000 1.000 1.000  0.750\n",
      "\n",
      "cvg.cvg_developer 21.000 0.952 0.905 0.952 0.952  0.714\n",
      "\n",
      "business.consumer_company 23.000 0.826 0.783 0.435 0.739  0.696\n",
      "\n",
      "people.person 2129.000 0.999 0.994 0.985 0.999  0.993\n",
      "\n",
      "computer.software 1.000 1.000 1.000 1.000 1.000  1.000\n",
      "\n",
      "sports.golfer 54.000 1.000 0.963 0.889 1.000  0.852\n",
      "\n",
      "education.field_of_study 9.000 0.778 0.556 0.333 0.556  0.222\n",
      "\n",
      "tv.tv_character 7.000 0.857 0.714 0.857 0.857  0.286\n",
      "\n",
      "sports.sports_league 465.000 0.981 0.970 0.957 0.953  0.927\n",
      "\n",
      "business.business_operation 172.000 0.977 0.942 0.948 0.942  0.872\n",
      "\n",
      "government.general_election 178.000 0.989 0.994 0.978 0.983  0.989\n",
      "\n",
      "music.composition 8.000 1.000 1.000 0.875 1.000  1.000\n",
      "\n",
      "fictional_universe.person_in_fiction 3.000 0.333 0.667 0.333 0.333  0.333\n",
      "\n",
      "baseball.baseball_position 19.000 1.000 1.000 0.947 1.000  1.000\n",
      "\n",
      "basketball.basketball_coach 9.000 1.000 0.667 1.000 1.000  0.111\n",
      "\n",
      "cricket.cricket_bowler 16.000 1.000 0.688 1.000 0.875  0.438\n",
      "\n",
      "award.award_category 9.000 0.889 0.889 0.889 0.889  0.889\n",
      "\n",
      "time.recurring_event 351.000 0.983 0.972 0.946 0.972  0.940\n",
      "\n",
      "tennis.tennis_tournament_champion 13.000 1.000 1.000 1.000 1.000  0.923\n",
      "\n",
      "film.film_distributor 6.000 1.000 0.833 0.833 1.000  0.667\n",
      "\n",
      "baseball.baseball_team 73.000 0.986 0.986 0.863 0.918  0.918\n",
      "\n",
      "religion.religious_leader 6.000 1.000 0.500 1.000 1.000  0.667\n",
      "\n",
      "cricket.cricket_team 24.000 1.000 0.958 0.833 0.875  0.625\n",
      "\n",
      "travel.tourist_attraction 6.000 0.833 0.667 0.833 1.000  1.000\n",
      "\n",
      "architecture.venue 139.000 0.942 0.921 0.935 0.950  0.906\n",
      "\n",
      "military.military_unit 6.000 1.000 1.000 0.167 0.833  0.833\n",
      "\n",
      "location.citytown 543.000 0.982 0.965 0.939 0.963  0.845\n",
      "\n",
      "american_football.football_player 31.000 1.000 0.903 0.935 0.968  0.774\n",
      "\n",
      "sports.sports_championship 13.000 0.923 0.923 0.231 0.692  0.769\n",
      "\n",
      "tv.tv_personality 16.000 0.688 0.500 0.688 0.625  0.125\n",
      "\n",
      "education.athletics_brand 17.000 1.000 0.882 0.824 0.882  0.235\n",
      "\n",
      "organization.membership_organization 6.000 0.833 1.000 1.000 0.833  0.667\n",
      "\n",
      "military.military_person 34.000 0.853 0.882 0.765 0.765  0.765\n",
      "\n",
      "film.film 65.000 0.985 0.954 0.923 0.969  0.708\n",
      "\n",
      "aviation.airport 21.000 1.000 0.952 0.952 0.952  0.952\n",
      "\n",
      "film.writer 34.000 0.912 0.853 0.882 0.941  0.471\n",
      "\n",
      "book.periodical 1.000 1.000 1.000 1.000 1.000  0.000\n",
      "\n",
      "soccer.football_position 10.000 1.000 1.000 0.900 1.000  1.000\n",
      "\n",
      "sports.school_sports_team 53.000 0.981 1.000 0.906 0.925  0.887\n",
      "\n",
      "media_common.media_genre 19.000 1.000 0.947 0.947 1.000  1.000\n",
      "\n",
      "sports.cyclist 15.000 1.000 1.000 0.933 1.000  0.800\n",
      "\n",
      "government.governmental_body 5.000 0.800 0.600 0.600 0.600  0.800\n",
      "\n",
      "broadcast.artist 15.000 0.733 0.533 0.600 0.667  0.267\n",
      "\n",
      "sports.sports_team 2184.000 0.993 0.989 0.987 0.986  0.955\n",
      "\n",
      "sports.professional_sports_team 137.000 1.000 1.000 0.839 0.934  0.949\n",
      "\n",
      "american_football.football_team 30.000 1.000 0.967 0.633 0.833  0.600\n",
      "\n",
      "soccer.football_team 1239.000 0.991 0.986 0.981 0.986  0.911\n",
      "\n",
      "olympics.olympic_event_competition 48.000 1.000 1.000 1.000 1.000  1.000\n",
      "\n",
      "martial_arts.martial_artist 4.000 0.750 0.500 0.750 0.750  0.500\n",
      "\n",
      "automotive.model 17.000 1.000 1.000 1.000 1.000  1.000\n",
      "\n",
      "award.award_ceremony 25.000 1.000 1.000 0.960 1.000  0.640\n",
      "\n",
      "biology.organism_classification 13.000 0.923 0.846 0.769 0.846  0.615\n",
      "\n",
      "government.u_s_congressperson 246.000 0.996 0.988 0.992 0.996  1.000\n",
      "\n",
      "architecture.building 7.000 1.000 0.571 0.714 0.857  0.429\n",
      "\n",
      "music.performance_role 1.000 1.000 1.000 1.000 1.000  1.000\n",
      "\n",
      "tv.tv_actor 65.000 0.923 0.938 0.862 0.908  0.769\n",
      "\n",
      "education.university 114.000 0.982 0.965 0.939 0.930  0.947\n",
      "\n",
      "sports.sports_league_season 525.000 0.990 0.979 0.954 0.990  0.964\n",
      "\n",
      "geography.mountain 9.000 1.000 1.000 0.778 1.000  0.556\n",
      "\n",
      "film.actor 84.000 0.905 0.881 0.833 0.845  0.607\n",
      "\n",
      "american_football.football_coach 7.000 0.857 0.714 0.286 0.714  0.143\n",
      "\n",
      "government.parliamentary_election 25.000 1.000 1.000 0.400 1.000  1.000\n",
      "\n",
      "location.us_state 33.000 1.000 1.000 0.970 1.000  1.000\n",
      "\n",
      "location.country 381.000 1.000 1.000 0.945 0.992  0.979\n",
      "\n",
      "sports.pro_athlete 828.000 0.981 0.959 0.964 0.987  0.926\n",
      "\n",
      "aviation.aircraft_model 11.000 1.000 0.909 1.000 1.000  0.909\n",
      "\n",
      "basketball.basketball_team 60.000 1.000 0.967 0.933 0.967  0.800\n",
      "\n",
      "royalty.monarch 3.000 0.667 0.667 0.667 0.667  0.667\n",
      "\n",
      "soccer.football_league 176.000 1.000 0.994 0.989 0.983  0.977\n",
      "\n",
      "cricket.cricket_player 29.000 1.000 0.966 0.966 1.000  0.655\n",
      "\n",
      "award.competition 65.000 0.985 0.954 0.954 0.938  0.723\n",
      "\n",
      "baseball.baseball_player 39.000 0.974 0.974 0.897 0.949  0.872\n",
      "\n",
      "broadcast.broadcast 26.000 1.000 1.000 0.962 0.962  1.000\n",
      "\n",
      "film.person_or_entity_appearing_in_film 54.000 0.759 0.611 0.704 0.722  0.407\n",
      "\n",
      "tv.tv_network 35.000 0.971 0.943 1.000 0.943  0.943\n",
      "\n",
      "ice_hockey.hockey_player 58.000 0.983 1.000 0.948 0.983  0.948\n",
      "\n",
      "film.director 85.000 0.976 0.953 0.918 0.976  0.859\n",
      "\n",
      "sports.sport 18.000 1.000 1.000 0.889 0.889  0.778\n",
      "\n",
      "language.human_language 18.000 1.000 0.944 0.889 0.889  0.944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t,i in type_vocab.items():\n",
    "    print('%s %.3f %.3f %.3f %.3f %.3f  %.3f'%(t, per_type_instance_num[i], per_type_accuracy[0][i], per_type_accuracy[1][i], per_type_accuracy[2][i], per_type_accuracy[3][i], per_type_accuracy[4][i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/CT/dev_per_type_result.csv', 'w') as f:\n",
    "    for t,i in type_vocab.items():\n",
    "        f.write('%s,%d'%(t, per_type_instance_num[i]))\n",
    "        for j in range(5):\n",
    "            f.write(',%.3f,%.3f,%.3f'%(per_type_f1[j][i],per_type_precision[j][i],per_type_recall[j][i]))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prediction_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9459584972991469,\n",
       " 1: 0.9291703659859919,\n",
       " 2: 0.8933839637797575,\n",
       " 3: 0.9254248876733736,\n",
       " 4: 0.8715658479062649}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9461666340700176,\n",
       " 1: 0.93782048090805,\n",
       " 2: 0.8899180447117017,\n",
       " 3: 0.9247474501000439,\n",
       " 4: 0.8954939162713962}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.945750452079566,\n",
       " 1: 0.9206783637163384,\n",
       " 2: 0.8968769854845804,\n",
       " 3: 0.9261033185083818,\n",
       " 4: 0.8488832412883046}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
